{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('cs224n': conda)",
   "metadata": {
    "interpreter": {
     "hash": "976ac0e44a77ecebd9924796002391647c6712319b88e0f45a893d4da7082770"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#The ESIM seems complex, let's make it first\n",
    "#following almostly copied from yjqiang\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_size, bidirectional)\n",
    "\n",
    "    def forward(self, tensor_sentences, length_list):\n",
    "        packed_sentences = pack_padded_sequence(tensor_sentences, length_list, batch_first=True, enforce_sorted=False)\n",
    "        output, _ = self.bilstm(packed_sentences)\n",
    "        result, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        return result"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "source": [
    "![alt text](encoder.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](whatesimcando.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class LocalInferenceModeling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=2)  # -1\n",
    "\n",
    "    def attention(self, x1_bar, length_list1, x2_bar, length_list2):\n",
    "        e = torch.bmm(x1_bar, x2_bar.transpose(1, 2))  # shape: (batch_size, max_sentence_length1, max_sentence_length2)\n",
    "\n",
    "        batch_size, max_sentence_length1, max_sentence_length2 = e.shape\n",
    "\n",
    "        #to get rid of pad\n",
    "        mask1 = torch.ge(torch.arange(max_sentence_length1).expand(batch_size, -1), seq_lengths1.unsqueeze(-1))\n",
    "        mask2 = torch.ge(torch.arange(max_sentence_length2).expand(batch_size, -1), seq_lengths2.unsqueeze(-1))\n",
    "\n",
    "        softmax_e = self.softmax(e.masked_fill(mask2.unsqueeze(1), float('-inf')))\n",
    "        x1_tilde = torch.bmm(softmax_e, x2_bar)\n",
    "\n",
    "        softmax_e = self.softmax(e.transpose(1, 2).masked_fill(mask1.unsqueeze(1), float('-inf')))\n",
    "        x2_tilde = torch.bmm(softmax_e, x1_bar) \n",
    "        return x1_tilde, x2_tilde\n",
    "\n",
    "    @staticmethod\n",
    "    def enhancement(x_bar:, x_tilde):\n",
    "        return torch.cat([x_bar, x_tilde, x_bar - x_tilde, x_bar * x_tilde], dim=-1)\n",
    "\n",
    "    def forward(self, x1_bar, length_list1, x2_bar, length_list2):\n",
    "        x1_tilde, x2_tilde = self.attention(x1_bar, length_list1, x2_bar, length_list2)\n",
    "        return self.enhancement(x1_bar, x1_tilde), self.enhancement(x2_bar, x2_tilde)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "![alt text](attention1.png)\n",
    "![alt text](attention2.png)\n",
    "![alt text](enhance.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, class_num):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_size, class_num)\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.tanh(self.fc1(x)))\n",
    "\n",
    "class InferenceComposition(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, class_num):\n",
    "        super().__init__()\n",
    "        self.F = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.BiLSTM = BiLSTM(input_size=hidden_size, hidden_size=hidden_size // 2)\n",
    "\n",
    "        self.MLP = MLP(in_features=4 * hidden_size, hidden_features=hidden_size, class_num=class_num)\n",
    "        self.loss_func = self.MLP.loss_func\n",
    "\n",
    "    def handle_x(self, m_x, length_list):\n",
    "        v_x_t = self.BiLSTM(self.relu(self.F(m_x)), seq_lengths)\n",
    "\n",
    "        max_sentence_length = m_x.shape[1]\n",
    "        v_x_t_transpose = v_x_t.transpose(1, 2)\n",
    "        v_x_avg = F.avg_pool1d(v_x_t_transpose, kernel_size=max_sentence_length).squeeze(-1)\n",
    "        v_x_max = F.max_pool1d(v_x_t_transpose, kernel_size=max_sentence_length).squeeze(-1)\n",
    "        return torch.cat([v_x_avg, v_x_max], dim=1)\n",
    "\n",
    "    def forward(self, m_x1: torch.Tensor, seq_lengths1: torch.Tensor, m_x2: torch.Tensor, seq_lengths2: torch.Tensor) -> torch.Tensor:\n",
    "        v = torch.cat([self.handle_x(m_x1, seq_lengths1), self.handle_x(m_x2, seq_lengths2)], dim=-1)  # shape: (batch_size, 4 * hidden_size)  \n",
    "        return self.MLP.get_scores(v)\n",
    "\n",
    "\n",
    "class ESIM(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_dim, num_layers, embedding):\n",
    "        super().__init__()\n",
    "        if embedding:\n",
    "            self.embedding = embedding\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        self.BiLSTM=BiLSTM(embedding_dim, vocab_dim, True)\n",
    "        self.LocalInterenceModeling=LocalInferenceModeling()\n",
    "        self.inference_composition = InferenceComposition(input_size=hidden_size*4, hidden_size=hidden_size, class_num=class_num)\n",
    "        self.loss_func = self.inference_composition.loss_func\n",
    "        \n",
    "    def forward(self, x1, length_list1, x2, length_list2):\n",
    "        x1 = self.embedding(x1)  # 论文中的 a；shape: (batch_size, max_sentence_length1, embedding_size)\n",
    "        x2 = self.embedding(x2)  # 论文中的 b；shape: (batch_size, max_sentence_length2, embedding_size)\n",
    "\n",
    "        # 3.1  INPUT ENCODING\n",
    "        x1_bar = self.BiLSTM(x1, lengths_list1)  # 论文中的 a_bar；shape: (batch_size, max_sentence_length1, hidden_size)\n",
    "        x2_bar = self.BiLSTM(x2, lengths_list2)  # 论文中的 b_bar；shape: (batch_size, max_sentence_length2, hidden_size)\n",
    "\n",
    "        # 3.2 Local Inference Modeling\n",
    "        m_x1, m_x2 = self.local_inference_modeling.forward(x1_bar, length_list1, x2_bar, length_list2)  # 论文中的 ma/mb；shape: (batch_size, max_sentence_length_i, hidden_size*4)\n",
    "\n",
    "        # 3.3 INFERENCE COMPOSITION\n",
    "        scores = self.inference_composition(m_x1, length_list1, m_x2, length_list2)  # scores shape: (batch_size, class_num\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#too tedious ... let's take a break ...\n"
   ]
  }
 ]
}